{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b37948-4b02-4c2a-98f7-4daf0621a786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [649 lines of output]\n",
      "  Partial import of sklearn during the build process.\n",
      "  test_program.c\n",
      "  Generating code\n",
      "  Finished generating code\n",
      "  test_program.c\n",
      "  LINK : warning LNK4044: unrecognized option '/openmp'; ignored\n",
      "  Generating code\n",
      "  Finished generating code\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      # particularly tiny on Windows/MSVC.\n",
      "      # It corresponds to the maximum representable value for\n",
      "      # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "      RAND_R_MAX = 2147483647\n",
      "  \n",
      "  cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                  ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pxd:19:33: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      # It corresponds to the maximum representable value for\n",
      "      # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "      RAND_R_MAX = 2147483647\n",
      "  \n",
      "  cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                   cnp.int_t n_samples,\n",
      "                                  ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pxd:20:33: 'int_t' is not a type identifier\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "    File \"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1238, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\linear_model\\_cd_fast.pyx\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      # particularly tiny on Windows/MSVC.\n",
      "      # It corresponds to the maximum representable value for\n",
      "      # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "      RAND_R_MAX = 2147483647\n",
      "  \n",
      "  cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                  ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pxd:19:33: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      # It corresponds to the maximum representable value for\n",
      "      # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "      RAND_R_MAX = 2147483647\n",
      "  \n",
      "  cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                   cnp.int_t n_samples,\n",
      "                                  ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pxd:20:33: 'int_t' is not a type identifier\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "    File \"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1238, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\tree\\_utils.pyx\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      # particularly tiny on Windows/MSVC.\n",
      "      # It corresponds to the maximum representable value for\n",
      "      # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "      RAND_R_MAX = 2147483647\n",
      "  \n",
      "  cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                  ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pxd:19:33: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      # It corresponds to the maximum representable value for\n",
      "      # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "      RAND_R_MAX = 2147483647\n",
      "  \n",
      "  cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                   cnp.int_t n_samples,\n",
      "                                  ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pxd:20:33: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "  from . import check_random_state\n",
      "  \n",
      "  cdef UINT32_t DEFAULT_SEED = 1\n",
      "  \n",
      "  \n",
      "  cpdef _sample_without_replacement_check_input(cnp.int_t n_population,\n",
      "                                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:22:46: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "  \n",
      "  cdef UINT32_t DEFAULT_SEED = 1\n",
      "  \n",
      "  \n",
      "  cpdef _sample_without_replacement_check_input(cnp.int_t n_population,\n",
      "                                                cnp.int_t n_samples):\n",
      "                                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:23:46: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "                           'n_samples, got n_samples > n_population (%s > %s)'\n",
      "                           % (n_samples, n_population))\n",
      "  \n",
      "  \n",
      "  cpdef _sample_without_replacement_with_tracking_selection(\n",
      "          cnp.int_t n_population,\n",
      "         ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:36:8: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "                           % (n_samples, n_population))\n",
      "  \n",
      "  \n",
      "  cpdef _sample_without_replacement_with_tracking_selection(\n",
      "          cnp.int_t n_population,\n",
      "          cnp.int_t n_samples,\n",
      "         ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:37:8: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          out[i] = j\n",
      "  \n",
      "      return np.asarray(out)\n",
      "  \n",
      "  \n",
      "  cpdef _sample_without_replacement_with_pool(cnp.int_t n_population,\n",
      "                                             ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:100:44: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "  \n",
      "      return np.asarray(out)\n",
      "  \n",
      "  \n",
      "  cpdef _sample_without_replacement_with_pool(cnp.int_t n_population,\n",
      "                                              cnp.int_t n_samples,\n",
      "                                             ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:101:44: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "  \n",
      "      return np.asarray(out)\n",
      "  \n",
      "  \n",
      "  cpdef _sample_without_replacement_with_reservoir_sampling(\n",
      "      cnp.int_t n_population,\n",
      "     ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:157:4: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      return np.asarray(out)\n",
      "  \n",
      "  \n",
      "  cpdef _sample_without_replacement_with_reservoir_sampling(\n",
      "      cnp.int_t n_population,\n",
      "      cnp.int_t n_samples,\n",
      "     ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:158:4: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "              out[j] = i\n",
      "  \n",
      "      return np.asarray(out)\n",
      "  \n",
      "  \n",
      "  cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                  ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:216:33: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "  \n",
      "      return np.asarray(out)\n",
      "  \n",
      "  \n",
      "  cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                   cnp.int_t n_samples,\n",
      "                                  ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:217:33: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      out : ndarray of shape (n_samples,)\n",
      "          The sampled subsets of integer.\n",
      "      \"\"\"\n",
      "      _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \n",
      "      cdef cnp.int_t i\n",
      "          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:79:9: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          The sampled subsets of integer.\n",
      "      \"\"\"\n",
      "      _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \n",
      "      cdef cnp.int_t i\n",
      "      cdef cnp.int_t j\n",
      "          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:80:9: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      \"\"\"\n",
      "      _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \n",
      "      cdef cnp.int_t i\n",
      "      cdef cnp.int_t j\n",
      "      cdef cnp.int_t[::1] out = np.empty((n_samples, ), dtype=int)\n",
      "          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:81:9: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      out : ndarray of shape (n_samples,)\n",
      "          The sampled subsets of integer.\n",
      "      \"\"\"\n",
      "      _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \n",
      "      cdef cnp.int_t i\n",
      "          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:134:9: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          The sampled subsets of integer.\n",
      "      \"\"\"\n",
      "      _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \n",
      "      cdef cnp.int_t i\n",
      "      cdef cnp.int_t j\n",
      "          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:135:9: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      \"\"\"\n",
      "      _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \n",
      "      cdef cnp.int_t i\n",
      "      cdef cnp.int_t j\n",
      "      cdef cnp.int_t[::1] out = np.empty((n_samples,), dtype=int)\n",
      "          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:136:9: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \n",
      "      cdef cnp.int_t i\n",
      "      cdef cnp.int_t j\n",
      "      cdef cnp.int_t[::1] out = np.empty((n_samples,), dtype=int)\n",
      "      cdef cnp.int_t[::1] pool = np.empty((n_population,), dtype=int)\n",
      "          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:137:9: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          necessarily random. Use a random permutation of the array if the order\n",
      "          of the items has to be randomized.\n",
      "      \"\"\"\n",
      "      _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \n",
      "      cdef cnp.int_t i\n",
      "          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:194:9: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          of the items has to be randomized.\n",
      "      \"\"\"\n",
      "      _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \n",
      "      cdef cnp.int_t i\n",
      "      cdef cnp.int_t j\n",
      "          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:195:9: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      \"\"\"\n",
      "      _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \n",
      "      cdef cnp.int_t i\n",
      "      cdef cnp.int_t j\n",
      "      cdef cnp.int_t[::1] out = np.empty((n_samples, ), dtype=int)\n",
      "          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:196:9: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      # 054289.html\n",
      "      #\n",
      "      for i in range(n_samples):\n",
      "          out[i] = i\n",
      "  \n",
      "      for i from n_samples <= i < n_population:\n",
      "     ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pyx:208:4: Compiler crash in AnalyseExpressionsTransform\n",
      "  \n",
      "  ModuleNode.body = StatListNode(_random.pyx:13:0)\n",
      "  StatListNode.stats[8] = StatListNode(_random.pyx:156:6)\n",
      "  StatListNode.stats[0] = CFuncDefNode(_random.pyx:156:6,\n",
      "      args = [...]/3,\n",
      "      doc = 'Sample integers without replacement.\\n\\n    Select n_samples integers from the set [0, n_population) without\\n    replacement.\\n\\n    Time complexity of\\n        O((n_population - n_samples) * O(np.random.randint) + n_samples)\\n    Space complexity of O(n_samples)\\n\\n\\n    Parameters\\n    ----------\\n    n_population : int\\n        The size of the set to sample from.\\n\\n    n_samples : int\\n         The number of integer to sample.\\n\\n    random_state : int, RandomState instance or None, default=None\\n        If int, random_state is the seed used by the random number generator;\\n        If RandomState instance, random_state is the random number generator;\\n        If None, the random number generator is the RandomState instance used\\n        by `np.random`.\\n\\n    Returns\\n    -------\\n    out : ndarray of shape (n_samples,)\\n        The sampled subsets of integer. The order of the items is not\\n        necessarily random. Use a random permutation of the array if the order\\n        of the items has to be randomized.\\n    ',\n",
      "      modifiers = [...]/0,\n",
      "      overridable = 1,\n",
      "      visibility = 'private')\n",
      "  File 'Nodes.py', line 435, in analyse_expressions: StatListNode(_random.pyx:161:4,\n",
      "      is_terminator = True)\n",
      "  File 'Nodes.py', line 6853, in analyse_expressions: ForFromStatNode(_random.pyx:208:4,\n",
      "      relation1 = '<=',\n",
      "      relation2 = '<')\n",
      "  File 'Nodes.py', line 6875, in set_up_loop: ForFromStatNode(_random.pyx:208:4,\n",
      "      relation1 = '<=',\n",
      "      relation2 = '<')\n",
      "  \n",
      "  Compiler crash traceback from this point on:\n",
      "    File \"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Nodes.py\", line 6875, in set_up_loop\n",
      "      loop_type = PyrexTypes.widest_numeric_type(loop_type, self.bound1.type)\n",
      "    File \"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Compiler\\PyrexTypes.py\", line 4481, in widest_numeric_type\n",
      "      elif type1.rank < type2.rank:\n",
      "                        ^^^^^^^^^^\n",
      "  AttributeError: 'ErrorType' object has no attribute 'rank'\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "    File \"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1238, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\utils\\_random.pyx\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      # particularly tiny on Windows/MSVC.\n",
      "      # It corresponds to the maximum representable value for\n",
      "      # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "      RAND_R_MAX = 2147483647\n",
      "  \n",
      "  cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                  ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pxd:19:33: 'int_t' is not a type identifier\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      # It corresponds to the maximum representable value for\n",
      "      # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "      RAND_R_MAX = 2147483647\n",
      "  \n",
      "  cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                   cnp.int_t n_samples,\n",
      "                                  ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_random.pxd:20:33: 'int_t' is not a type identifier\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "    File \"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1238, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\utils\\_seq_dataset.pyx\n",
      "  Compiling sklearn\\__check_build\\_check_build.pyx because it changed.\n",
      "  Compiling sklearn\\_isotonic.pyx because it changed.\n",
      "  Compiling sklearn\\_loss\\_loss.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_dbscan_inner.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_hierarchical_fast.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_common.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_lloyd.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_elkan.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_minibatch.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_hdbscan\\_linkage.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_hdbscan\\_reachability.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_hdbscan\\_tree.pyx because it changed.\n",
      "  Compiling sklearn\\datasets\\_svmlight_format_fast.pyx because it changed.\n",
      "  Compiling sklearn\\decomposition\\_online_lda_fast.pyx because it changed.\n",
      "  Compiling sklearn\\decomposition\\_cdnmf_fast.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_gradient_boosting.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx because it changed.\n",
      "  Compiling sklearn\\feature_extraction\\_hashing_fast.pyx because it changed.\n",
      "  Compiling sklearn\\linear_model\\_cd_fast.pyx because it changed.\n",
      "  Compiling sklearn\\linear_model\\_sgd_fast.pyx because it changed.\n",
      "  Compiling sklearn\\linear_model\\_sag_fast.pyx because it changed.\n",
      "  Compiling sklearn\\manifold\\_utils.pyx because it changed.\n",
      "  Compiling sklearn\\manifold\\_barnes_hut_tsne.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_pairwise_fast.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_dist_metrics.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_pairwise_distances_reduction\\_middle_term_computer.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_pairwise_distances_reduction\\_base.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin_classmode.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_pairwise_distances_reduction\\_radius_neighbors.pyx because it changed.\n",
      "  Compiling sklearn\\preprocessing\\_csr_polynomial_expansion.pyx because it changed.\n",
      "  Compiling sklearn\\preprocessing\\_target_encoder_fast.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_ball_tree.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_kd_tree.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_partition_nodes.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_quad_tree.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_newrand.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_libsvm.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_liblinear.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_libsvm_sparse.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_tree.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_splitter.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_criterion.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_utils.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\sparsefuncs_fast.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_cython_blas.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\arrayfuncs.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\murmurhash.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_fast_dict.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_openmp_helpers.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_seq_dataset.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_weight_vector.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_random.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_logistic_sigmoid.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_typedefs.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_heap.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_sorting.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_vector_sentinel.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_isfinite.pyx because it changed.\n",
      "  [ 1/68] Cythonizing sklearn\\__check_build\\_check_build.pyx\n",
      "  [ 2/68] Cythonizing sklearn\\_isotonic.pyx\n",
      "  [ 3/68] Cythonizing sklearn\\_loss\\_loss.pyx\n",
      "  [ 4/68] Cythonizing sklearn\\cluster\\_dbscan_inner.pyx\n",
      "  [ 5/68] Cythonizing sklearn\\cluster\\_hdbscan\\_linkage.pyx\n",
      "  [ 6/68] Cythonizing sklearn\\cluster\\_hdbscan\\_reachability.pyx\n",
      "  [ 7/68] Cythonizing sklearn\\cluster\\_hdbscan\\_tree.pyx\n",
      "  [ 8/68] Cythonizing sklearn\\cluster\\_hierarchical_fast.pyx\n",
      "  [ 9/68] Cythonizing sklearn\\cluster\\_k_means_common.pyx\n",
      "  [10/68] Cythonizing sklearn\\cluster\\_k_means_elkan.pyx\n",
      "  [11/68] Cythonizing sklearn\\cluster\\_k_means_lloyd.pyx\n",
      "  [12/68] Cythonizing sklearn\\cluster\\_k_means_minibatch.pyx\n",
      "  [13/68] Cythonizing sklearn\\datasets\\_svmlight_format_fast.pyx\n",
      "  [14/68] Cythonizing sklearn\\decomposition\\_cdnmf_fast.pyx\n",
      "  [15/68] Cythonizing sklearn\\decomposition\\_online_lda_fast.pyx\n",
      "  [16/68] Cythonizing sklearn\\ensemble\\_gradient_boosting.pyx\n",
      "  [17/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx\n",
      "  [18/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx\n",
      "  [19/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx\n",
      "  [20/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx\n",
      "  [21/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx\n",
      "  [22/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx\n",
      "  [23/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  [24/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx\n",
      "  [25/68] Cythonizing sklearn\\feature_extraction\\_hashing_fast.pyx\n",
      "  [26/68] Cythonizing sklearn\\linear_model\\_cd_fast.pyx\n",
      "  [27/68] Cythonizing sklearn\\linear_model\\_sag_fast.pyx\n",
      "  [28/68] Cythonizing sklearn\\linear_model\\_sgd_fast.pyx\n",
      "  [29/68] Cythonizing sklearn\\manifold\\_barnes_hut_tsne.pyx\n",
      "  [30/68] Cythonizing sklearn\\manifold\\_utils.pyx\n",
      "  [31/68] Cythonizing sklearn\\metrics\\_dist_metrics.pyx\n",
      "  [32/68] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\n",
      "  [33/68] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin_classmode.pyx\n",
      "  [34/68] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction\\_base.pyx\n",
      "  [35/68] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\n",
      "  [36/68] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction\\_middle_term_computer.pyx\n",
      "  [37/68] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction\\_radius_neighbors.pyx\n",
      "  [38/68] Cythonizing sklearn\\metrics\\_pairwise_fast.pyx\n",
      "  [39/68] Cythonizing sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx\n",
      "  [40/68] Cythonizing sklearn\\neighbors\\_ball_tree.pyx\n",
      "  [41/68] Cythonizing sklearn\\neighbors\\_kd_tree.pyx\n",
      "  [42/68] Cythonizing sklearn\\neighbors\\_partition_nodes.pyx\n",
      "  [43/68] Cythonizing sklearn\\neighbors\\_quad_tree.pyx\n",
      "  [44/68] Cythonizing sklearn\\preprocessing\\_csr_polynomial_expansion.pyx\n",
      "  [45/68] Cythonizing sklearn\\preprocessing\\_target_encoder_fast.pyx\n",
      "  [46/68] Cythonizing sklearn\\svm\\_liblinear.pyx\n",
      "  [47/68] Cythonizing sklearn\\svm\\_libsvm.pyx\n",
      "  [48/68] Cythonizing sklearn\\svm\\_libsvm_sparse.pyx\n",
      "  [49/68] Cythonizing sklearn\\svm\\_newrand.pyx\n",
      "  [50/68] Cythonizing sklearn\\tree\\_criterion.pyx\n",
      "  [51/68] Cythonizing sklearn\\tree\\_splitter.pyx\n",
      "  [52/68] Cythonizing sklearn\\tree\\_tree.pyx\n",
      "  [53/68] Cythonizing sklearn\\tree\\_utils.pyx\n",
      "  [54/68] Cythonizing sklearn\\utils\\_cython_blas.pyx\n",
      "  [55/68] Cythonizing sklearn\\utils\\_fast_dict.pyx\n",
      "  [56/68] Cythonizing sklearn\\utils\\_heap.pyx\n",
      "  [57/68] Cythonizing sklearn\\utils\\_isfinite.pyx\n",
      "  [58/68] Cythonizing sklearn\\utils\\_logistic_sigmoid.pyx\n",
      "  [59/68] Cythonizing sklearn\\utils\\_openmp_helpers.pyx\n",
      "  [60/68] Cythonizing sklearn\\utils\\_random.pyx\n",
      "  [61/68] Cythonizing sklearn\\utils\\_seq_dataset.pyx\n",
      "  [62/68] Cythonizing sklearn\\utils\\_sorting.pyx\n",
      "  [63/68] Cythonizing sklearn\\utils\\_typedefs.pyx\n",
      "  [64/68] Cythonizing sklearn\\utils\\_vector_sentinel.pyx\n",
      "  [65/68] Cythonizing sklearn\\utils\\_weight_vector.pyx\n",
      "  [66/68] Cythonizing sklearn\\utils\\arrayfuncs.pyx\n",
      "  [67/68] Cythonizing sklearn\\utils\\murmurhash.pyx\n",
      "  [68/68] Cythonizing sklearn\\utils\\sparsefuncs_fast.pyx\n",
      "  \u001b[1;35mmultiprocessing.pool.RemoteTraceback\u001b[0m: \u001b[35m\n",
      "  \"\"\"\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\anaconda\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n",
      "      result = (True, func(*args, **kwds))\n",
      "                      ~~~~^^^^^^^^^^^^^^^\n",
      "    File \"C:\\anaconda\\Lib\\multiprocessing\\pool.py\", line 48, in mapstar\n",
      "      return list(map(*args))\n",
      "    File \"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "    File \"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1238, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\linear_model\\_cd_fast.pyx\n",
      "  \"\"\"\u001b[0m\n",
      "  \n",
      "  The above exception was the direct cause of the following exception:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \u001b[35m\"C:\\anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "      \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "      \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "    File \u001b[35m\"C:\\anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "      json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                               \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    File \u001b[35m\"C:\\anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m175\u001b[0m, in \u001b[35mprepare_metadata_for_build_wheel\u001b[0m\n",
      "      return hook(metadata_directory, config_settings)\n",
      "    File \u001b[35m\"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m374\u001b[0m, in \u001b[35mprepare_metadata_for_build_wheel\u001b[0m\n",
      "      \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "      \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "    File \u001b[35m\"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "      \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "      \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    File \u001b[35m\"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "      \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "      \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m633\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m627\u001b[0m, in \u001b[35msetup_package\u001b[0m\n",
      "    File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m554\u001b[0m, in \u001b[35mconfigure_extension_modules\u001b[0m\n",
      "    File \u001b[35m\"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-install-0h8c6b8n\\scikit-learn_5f540f03db5d464a8eea8b647c73cb20\\sklearn\\_build_utils\\__init__.py\"\u001b[0m, line \u001b[35m80\u001b[0m, in \u001b[35mcythonize_extensions\u001b[0m\n",
      "      return cythonize(\n",
      "          extension,\n",
      "          nthreads=n_jobs,\n",
      "          compiler_directives=compiler_directives,\n",
      "      )\n",
      "    File \u001b[35m\"C:\\Users\\SAKSHI BADOLA\\AppData\\Local\\Temp\\pip-build-env-g_k8a6cr\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\"\u001b[0m, line \u001b[35m1106\u001b[0m, in \u001b[35mcythonize\u001b[0m\n",
      "      \u001b[31mresult.get\u001b[0m\u001b[1;31m(99999)\u001b[0m  # seconds\n",
      "      \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^\u001b[0m\n",
      "    File \u001b[35m\"C:\\anaconda\\Lib\\multiprocessing\\pool.py\"\u001b[0m, line \u001b[35m774\u001b[0m, in \u001b[35mget\u001b[0m\n",
      "      raise self._value\n",
      "  \u001b[1;35mCython.Compiler.Errors.CompileError\u001b[0m: \u001b[35msklearn\\linear_model\\_cd_fast.pyx\u001b[0m\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "C:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.3.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2025-12-03 20:09:50.039 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:50.754 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\anaconda\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-12-03 20:09:50.755 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:50.756 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:50.757 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:50.758 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:50.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:50.761 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:50.762 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:50.763 Session state does not function when running a script without `streamlit run`\n",
      "2025-12-03 20:09:50.765 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:50.766 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "C:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.3.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2025-12-03 20:09:52.024 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.025 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.026 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.027 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.029 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.030 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.031 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.033 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.033 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.034 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.035 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.037 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.038 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.039 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.040 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.041 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.043 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.044 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.045 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.047 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.048 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.049 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.050 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.052 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.053 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.054 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.056 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.058 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.064 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.069 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.070 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.096 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.100 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-03 20:09:52.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -U scikit-learn==1.3.2 imbalanced-learn==0.11.0 --quiet\n",
    "# ------------------------------------------------------------\n",
    "# STREAMLIT APP â€“ FULLY COMPATIBLE WITH TRAINED MODEL COLUMNS\n",
    "# ------------------------------------------------------------\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# LOAD MODELS, SCALER & COLUMNS\n",
    "# ------------------------------------------------------------\n",
    "model_files = {\n",
    "    \"Logistic Regression\": \"logistic.pkl\",\n",
    "    \"Decision Tree\": \"decision_tree.pkl\",\n",
    "    \"Random Forest\": \"random_forest.pkl\",\n",
    "    \"SVM\": \"svm.pkl\",\n",
    "    \"XGBoost\": \"xgb.pkl\"\n",
    "}\n",
    "\n",
    "def load_model(path):\n",
    "    return pickle.load(open(path, \"rb\"))\n",
    "\n",
    "model_columns = pickle.load(open(\"model_columns.pkl\", \"rb\"))\n",
    "scaler = pickle.load(open(\"scaler.pkl\", \"rb\"))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# UI LAYOUT\n",
    "# ------------------------------------------------------------\n",
    "st.title(\"ðŸ’³ Loan Default Prediction System\")\n",
    "st.write(\"Simple Inputs â†’ Full ML Model â†’ Accurate Prediction\")\n",
    "\n",
    "selected_model = st.selectbox(\"Select a Model\", list(model_files.keys()))\n",
    "model = load_model(model_files[selected_model])\n",
    "\n",
    "income = st.number_input(\"Income\", 0, 10000000, 150000)\n",
    "credit = st.number_input(\"Credit Amount\", 0, 20000000, 600000)\n",
    "annuity = st.number_input(\"Annuity\", 0, 500000, 25000)\n",
    "goods = st.number_input(\"Goods Price\", 0, 20000000, 600000)\n",
    "\n",
    "age = st.slider(\"Age\", 18, 70, 35)\n",
    "emp_years = st.slider(\"Years Employed\", 0, 45, 5)\n",
    "family = st.slider(\"Family Members\", 1, 15, 2)\n",
    "\n",
    "days_birth = -age * 365\n",
    "days_employed = -emp_years * 365\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# RECONSTRUCT FULL COLUMN SET\n",
    "# ------------------------------------------------------------\n",
    "full_data = pd.DataFrame(columns=model_columns)\n",
    "full_data.loc[0] = 0  # initialize all 200+ columns with zeros\n",
    "\n",
    "# Fill only the columns user provides\n",
    "full_data[\"AMT_INCOME_TOTAL\"] = income\n",
    "full_data[\"AMT_CREDIT\"] = credit\n",
    "full_data[\"AMT_ANNUITY\"] = annuity\n",
    "full_data[\"AMT_GOODS_PRICE\"] = goods\n",
    "full_data[\"DAYS_BIRTH\"] = days_birth\n",
    "full_data[\"DAYS_EMPLOYED\"] = days_employed\n",
    "full_data[\"CNT_FAM_MEMBERS\"] = family\n",
    "full_data[\"AGE_YEARS\"] = age\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# SCALE USING TRAINING SCALER\n",
    "# ------------------------------------------------------------\n",
    "scaled = scaler.transform(full_data)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# PREDICT\n",
    "# ------------------------------------------------------------\n",
    "if st.button(\"Predict Default Risk\"):\n",
    "    prob = model.predict_proba(scaled)[0][1]\n",
    "    risk = \"HIGH RISK\" if prob > 0.5 else \"LOW RISK\"\n",
    "\n",
    "    st.subheader(f\"Risk Level: {risk}\")\n",
    "    st.write(f\"Probability of Default: {prob:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70434e2-435a-4734-9c49-c9e7e04e369c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
